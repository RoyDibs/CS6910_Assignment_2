{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8032687,"sourceType":"datasetVersion","datasetId":4734841}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-05T18:29:20.491647Z","iopub.execute_input":"2024-04-05T18:29:20.491999Z","iopub.status.idle":"2024-04-05T18:29:33.753820Z","shell.execute_reply.started":"2024-04-05T18:29:20.491971Z","shell.execute_reply":"2024-04-05T18:29:33.752808Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\n\nwandb.login(key='208eb9fbdf5d2187fde3a83cdf51d2c458066577')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T18:31:09.803017Z","iopub.execute_input":"2024-04-05T18:31:09.803864Z","iopub.status.idle":"2024-04-05T18:31:09.994621Z","shell.execute_reply.started":"2024-04-05T18:31:09.803831Z","shell.execute_reply":"2024-04-05T18:31:09.993674Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdibakar\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\n\ndef get_transform(data_augmentation):\n    if data_augmentation:\n        transform = transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n            transforms.ToTensor(),     \n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    else:\n        # Regular transformations\n        transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    return transform\n\ndef load_dataset(train_folder, test_folder, transform):\n    train_dataset = datasets.ImageFolder(train_folder, transform=get_transform(transform))\n    test_dataset = datasets.ImageFolder(test_folder, transform=get_transform(False))\n    return train_dataset, test_dataset\n\ndef train(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n    for epoch in range(num_epochs):\n        model.train()  # Set the model to training mode\n        running_loss = 0.0\n        for i, (images, labels) in enumerate(train_loader):\n            if torch.cuda.is_available():\n                images, labels = images.cuda(), labels.cuda()\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            if (i + 1) % 240 == 0:  # Print every 100 batches\n#                 print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 10:.4f}\")\n                wandb.log({'Epoch': (epoch + 1)/num_epochs, 'Step': (i + 1)/(len(train_loader)), 'Loss': running_loss / 240})\n                running_loss = 0.0\n        # Validation loop\n        model.eval()  # Set the model to evaluation mode\n        \n        val_loss = 0.0\n        correct = 0\n        total = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                if torch.cuda.is_available():\n                    images, labels = images.cuda(), labels.cuda()\n\n                # Forward pass\n                outputs = model(images)\n                \n                # Calculate loss\n                loss = criterion(outputs, labels)\n                \n                # Update validation loss\n                val_loss += loss.item()\n\n                # Calculate accuracy\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n\n        # Calculate average validation loss and accuracy for the epoch\n        val_loss /= len(val_loader)\n        val_accuracy = correct / total * 100\n\n        wandb.log({'Val_Loss': val_loss, 'val_accuracy': val_accuracy})\n        \n\n\nclass CNN(nn.Module):\n    def __init__(self, hparams):\n        super(CNN, self).__init__()\n        self.hparams = hparams\n        num_conv_layers = hparams['num_conv_layers']\n        in_channels = 3\n        num_filters = hparams['num_filters']\n        kernel_size = hparams['kernel_size']  # Single integer value\n        num_classes = 10\n        num_neurons_dense = hparams['num_neurons_dense']\n        input_size = 224\n        filter_organization = hparams['filter_organization']\n        batch_normalization = hparams['batch_normalization']\n        dropout_prob = hparams['dropout_prob']\n        conv_activation = hparams['conv_activation']\n\n        self.conv_layers = nn.ModuleList()\n        self.num_conv_layers = num_conv_layers\n\n        # Add convolution layers\n        for i in range(num_conv_layers):\n            # Determine the number of filters for this layer based on filter_organization\n            if filter_organization == 'same':\n                out_channels = num_filters\n            elif filter_organization == 'double':\n                out_channels = num_filters * (2 ** i)\n            elif filter_organization == 'halve':\n                out_channels = num_filters // (2 ** i)\n            else:\n                raise ValueError(\"Invalid filter organization\")\n\n            # Determine padding value to maintain spatial dimensions\n            padding = kernel_size // 2 if kernel_size % 2 == 1 else (kernel_size - 1) // 2\n\n            # Add convolution layer with the same kernel size for all layers\n            conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n            self.conv_layers.append(conv_layer)\n\n            # Add batch normalization if enabled\n            if batch_normalization:\n                bn_layer = nn.BatchNorm2d(out_channels)\n                self.conv_layers.append(bn_layer)\n\n            in_channels = out_channels\n\n        # Add dropout layer after the last convolution layer\n        self.dropout_conv = nn.Dropout2d(p=dropout_prob)\n\n        # Calculate input size for dense layer\n        dense_input_size = out_channels * (input_size // (2 ** num_conv_layers)) ** 2\n\n        # Dense layer\n        self.dense = nn.Linear(dense_input_size, num_neurons_dense)\n\n        # Output layer\n        self.output = nn.Linear(num_neurons_dense, num_classes)\n\n    def forward(self, x):\n        # Convolution layers\n        for i, layer in enumerate(self.conv_layers):\n            x = layer(x)\n            if isinstance(layer, nn.Conv2d):\n                # Apply activation function dynamically\n                if self.hparams['conv_activation'] == 'relu':\n                    x = F.relu(x)\n                elif self.hparams['conv_activation'] == 'gelu':\n                    x = F.gelu(x)\n                elif self.hparams['conv_activation'] == 'mish':\n                    x = F.mish(x)\n                else:\n                    raise ValueError(\"Invalid convolutional activation function\")\n                \n                x = F.max_pool2d(x, 2)\n\n        # Flatten\n        x = torch.flatten(x, 1)\n\n        # Dense layer\n        x = F.relu(self.dense(x))\n\n        # Output layer (raw scores)\n        x = self.output(x)\n        return x\n\n# Define the hyperparameter sweep configuration\nsweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep inaturalist part',\n    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        'num_conv_layers': {'values': [5]},\n        'num_filters': {'values': [32, 64, 128]},\n        'kernel_size': {'values': [3, 5]},\n        'num_neurons_dense': {'values': [50, 100, 128]},\n        'filter_organization': {'values': ['same', 'double', 'halve']},\n        'data_augmentation': {'values': [False, True]},\n        'batch_normalization': {'values': [False, True]},\n        'dropout_prob': {'values': [0.0, 0.2, 0.3]},\n        'conv_activation': {'values': ['relu', 'gelu', 'mish']},\n        'max_epoch': {'values': [5 , 10]},\n    }\n}\n\n# Define the sweep\nsweep_id = wandb.sweep(sweep_config, project='CS6910_Assignment_2_partA')\n\ndef main():\n    \n    with wandb.init() as run:\n\n        run_name=\"-num_fil_\"+ str(wandb.config.num_filters) +\"-k_\"+ str(wandb.config.kernel_size) +\"-neuron_dense_\"+ str(wandb.config.num_neurons_dense) +\"-af_conv_\"+ str(wandb.config.conv_activation) +\"-fil_org_\"+ str(wandb.config.filter_organization) +\"-data_aug_\"+ str(wandb.config.data_augmentation) +\"-batch_norm_\"+ str(wandb.config.batch_normalization) +\"-drop_p_\"+ str(wandb.config.dropout_prob)\n        wandb.run.name=run_name\n        \n        hparams = wandb.config\n        \n        train_folder = '/kaggle/input/dataset/inaturalist_12K/train'\n        test_folder = '/kaggle/input/dataset/inaturalist_12K/val'\n        transform = get_transform(hparams['data_augmentation'])\n        train_dataset, test_dataset = load_dataset(train_folder, test_folder, transform)\n\n        # Define batch size for DataLoader\n        batch_size = 32\n\n        # Split train dataset into train and validation sets\n        train_indices, val_indices = train_test_split(list(range(len(train_dataset))), test_size=0.2, shuffle=True, stratify=train_dataset.targets)\n        train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n        val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n\n        # Create DataLoader for train and validation datasets\n        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n        val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\n        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n        print(\"Number of samples in train set after splitting:\", len(train_indices))\n        print(\"Number of samples in validation set after splitting:\", len(val_indices))\n\n        for images, labels in train_loader:\n            batch_size, in_channels, height, width = images.shape\n            num_classes = len(train_dataset.classes)\n            input_size = height, width\n            break \n\n        print(\"In channels:\", in_channels)\n        print(\"Number of classes:\", num_classes)\n        print(\"Input size (height, width):\", input_size)\n\n\n        # Create the model\n        model = CNN(hparams)\n\n        criterion = nn.CrossEntropyLoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        # checking if GPU is available\n        if torch.cuda.is_available():\n            model = model.cuda()\n            criterion = criterion.cuda()\n        train(model,criterion,optimizer,train_loader,val_loader, hparams['max_epoch'])\n\n# Run the sweep\nwandb.agent(sweep_id, function=main, count=50)\n# Finish the run\nwandb.finish()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-05T18:31:18.276543Z","iopub.execute_input":"2024-04-05T18:31:18.276901Z","iopub.status.idle":"2024-04-05T18:37:18.059146Z","shell.execute_reply.started":"2024-04-05T18:31:18.276872Z","shell.execute_reply":"2024-04-05T18:37:18.057946Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Create sweep with ID: hc2gewm6\nSweep URL: https://wandb.ai/dibakar/CS6910_Assignment_2_partA/sweeps/hc2gewm6\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: shgck3xp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_activation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_prob: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_183128-shgck3xp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dibakar/CS6910_Assignment_2_partA/runs/shgck3xp' target=\"_blank\">pretty-sweep-1</a></strong> to <a href='https://wandb.ai/dibakar/CS6910_Assignment_2_partA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dibakar/CS6910_Assignment_2_partA/sweeps/hc2gewm6' target=\"_blank\">https://wandb.ai/dibakar/CS6910_Assignment_2_partA/sweeps/hc2gewm6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dibakar/CS6910_Assignment_2_partA' target=\"_blank\">https://wandb.ai/dibakar/CS6910_Assignment_2_partA</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dibakar/CS6910_Assignment_2_partA/sweeps/hc2gewm6' target=\"_blank\">https://wandb.ai/dibakar/CS6910_Assignment_2_partA/sweeps/hc2gewm6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dibakar/CS6910_Assignment_2_partA/runs/shgck3xp' target=\"_blank\">https://wandb.ai/dibakar/CS6910_Assignment_2_partA/runs/shgck3xp</a>"},"metadata":{}},{"name":"stdout","text":"Number of samples in train set after splitting: 7999\nNumber of samples in validation set after splitting: 2000\nIn channels: 3\nNumber of classes: 10\nInput size (height, width): (224, 224)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁█</td></tr><tr><td>Loss</td><td>█▁</td></tr><tr><td>Step</td><td>▁▁</td></tr><tr><td>Val_Loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>0.4</td></tr><tr><td>Loss</td><td>2.30362</td></tr><tr><td>Step</td><td>0.96</td></tr><tr><td>Val_Loss</td><td>2.30365</td></tr><tr><td>val_accuracy</td><td>9.9</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pretty-sweep-1</strong> at: <a href='https://wandb.ai/dibakar/CS6910_Assignment_2_partA/runs/shgck3xp' target=\"_blank\">https://wandb.ai/dibakar/CS6910_Assignment_2_partA/runs/shgck3xp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240405_183128-shgck3xp/logs</code>"},"metadata":{}}]}]}