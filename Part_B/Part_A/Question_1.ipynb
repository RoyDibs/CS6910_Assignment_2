{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWH68vJhcNAX",
        "outputId": "5a4a3b76-db8c-47c0-92c5-3099867be788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv_layers): ModuleList(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Dropout2d(p=0.2, inplace=False)\n",
            "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (3): Dropout2d(p=0.2, inplace=False)\n",
            "    (4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (5): Dropout2d(p=0.2, inplace=False)\n",
            "    (6): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): Dropout2d(p=0.2, inplace=False)\n",
            "    (8): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (9): Dropout2d(p=0.2, inplace=False)\n",
            "  )\n",
            "  (dense): Linear(in_features=1568, out_features=100, bias=True)\n",
            "  (dropout_dense): Dropout(p=0.2, inplace=False)\n",
            "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, hparams):\n",
        "        super(CNN, self).__init__()\n",
        "        self.hparams = hparams\n",
        "        num_conv_layers = hparams['num_conv_layers']\n",
        "        in_channels = 3\n",
        "        num_filters = hparams['num_filters']\n",
        "        kernel_size = hparams['kernel_size']  # Single integer value\n",
        "        num_classes = 10\n",
        "        num_neurons_dense = hparams['num_neurons_dense']\n",
        "        input_size = 224\n",
        "        filter_organization = hparams['filter_organization']\n",
        "        batch_normalization = hparams['batch_normalization']\n",
        "        dropout_prob = hparams['dropout_prob']\n",
        "        conv_activation = hparams['conv_activation']\n",
        "\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        self.num_conv_layers = num_conv_layers\n",
        "\n",
        "        # Add convolution layers\n",
        "        for i in range(num_conv_layers):\n",
        "            # Determine the number of filters for this layer based on filter_organization\n",
        "            if filter_organization == 'same':\n",
        "                out_channels = num_filters\n",
        "            elif filter_organization == 'double':\n",
        "                out_channels = num_filters * (2 ** i)\n",
        "            elif filter_organization == 'halve':\n",
        "                out_channels = num_filters // (2 ** i)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid filter organization\")\n",
        "\n",
        "            # Determine padding value to maintain spatial dimensions\n",
        "            padding = kernel_size // 2 if kernel_size % 2 == 1 else (kernel_size - 1) // 2\n",
        "\n",
        "            # Add convolution layer with the same kernel size for all layers\n",
        "            conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
        "            self.conv_layers.append(conv_layer)\n",
        "\n",
        "            # Add batch normalization if enabled\n",
        "            if batch_normalization:\n",
        "                bn_layer = nn.BatchNorm2d(out_channels)\n",
        "                self.conv_layers.append(bn_layer)\n",
        "\n",
        "            # Add dropout layer\n",
        "            dropout_layer = nn.Dropout2d(p=dropout_prob)\n",
        "            self.conv_layers.append(dropout_layer)\n",
        "\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # Calculate input size for dense layer\n",
        "        dense_input_size = out_channels * (input_size // (2 ** num_conv_layers)) ** 2\n",
        "\n",
        "        # Dense layer\n",
        "        self.dense = nn.Linear(dense_input_size, num_neurons_dense)\n",
        "\n",
        "        # Dropout layer after dense layer\n",
        "        self.dropout_dense = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        # Output layer\n",
        "        self.output = nn.Linear(num_neurons_dense, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution layers\n",
        "        for layer in self.conv_layers:\n",
        "            # Apply the appropriate activation function\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                if self.hparams['conv_activation'] == 'relu':\n",
        "                    x = F.relu(layer(x))\n",
        "                elif self.hparams['conv_activation'] == 'gelu':\n",
        "                    x = F.gelu(layer(x))\n",
        "                elif self.hparams['conv_activation'] == 'silu':\n",
        "                    x = F.silu(layer(x))\n",
        "                elif self.hparams['conv_activation'] == 'mish':\n",
        "                    x = F.mish(layer(x))\n",
        "                else:\n",
        "                    raise ValueError(\"Invalid convolutional activation function specified\")\n",
        "            else:\n",
        "                x = layer(x)\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                x = F.max_pool2d(x, 2)\n",
        "\n",
        "        # Flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Dense layer with dropout\n",
        "        x = F.relu(self.dense(x))\n",
        "        x = self.dropout_dense(x)\n",
        "\n",
        "        # Output layer (raw scores)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "hparams = {\n",
        "    'num_conv_layers': 5,\n",
        "    'in_channels': 0,\n",
        "    'num_filters': 32,\n",
        "    'kernel_size': 5,\n",
        "    'num_classes': 0,\n",
        "    'num_neurons_dense': 100,\n",
        "    'input_size': 0,\n",
        "    'filter_organization': 'same',\n",
        "    'data_augmentation': False,\n",
        "    'batch_normalization': False,  # Set to True or False as needed\n",
        "    'dropout_prob': 0.2,\n",
        "    'conv_activation': 'mish'\n",
        "}\n",
        "model = CNN(hparams)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IOb4rImgdcUy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}