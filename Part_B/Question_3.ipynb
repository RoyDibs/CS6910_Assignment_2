{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8044281,"sourceType":"datasetVersion","datasetId":4743104}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\n\ndef load_dataset(train_folder, test_folder, transform):\n    train_dataset = datasets.ImageFolder(train_folder, transform=transform)\n    test_dataset = datasets.ImageFolder(test_folder, transform=transform)\n    return train_dataset, test_dataset\n\ndef train(model, criterion, optimizer, train_loader, val_loader,test_loader, num_epochs):\n    for epoch in range(num_epochs):\n        model.train()  # Set the model to training mode\n        running_loss = 0.0\n        for i, (images, labels) in enumerate(train_loader):\n            if torch.cuda.is_available():\n                images, labels = images.cuda(), labels.cuda()\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            if (i + 1) % 100 == 0:\n                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}\")\n                running_loss = 0.0\n\n        # Validation loop\n        model.eval()  # Set the model to evaluation mode\n        val_loss = 0.0\n        correct = 0\n        total = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                if torch.cuda.is_available():\n                    images, labels = images.cuda(), labels.cuda()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n\n        # Calculate average validation loss and accuracy for the epoch\n        val_loss /= len(val_loader)\n        val_accuracy = correct / total * 100\n        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n    with torch.no_grad():\n        for images, labels in test_loader:\n            if torch.cuda.is_available():\n                images, labels = images.cuda(), labels.cuda()\n\n            # Forward pass\n            outputs = model(images)\n\n            # Calculate loss\n            test_loss = criterion(outputs, labels)\n\n            # Update validation loss\n            test_loss += test_loss.item()\n\n            # Calculate accuracy\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n        # Calculate average validation loss and accuracy for the epoch\n        test_loss /= len(test_loader)\n        test_accuracy = correct / total * 100\n\n#         wandb.log({'Val_Loss': val_loss, 'val_accuracy': val_accuracy})\n        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n    \n    \n# Define the transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load the dataset\ntrain_folder = '/kaggle/input/dataset-cs6910-a2/inaturalist_12K/train'\ntest_folder = '/kaggle/input/dataset-cs6910-a2/inaturalist_12K/val'\ntrain_dataset, test_dataset = load_dataset(train_folder, test_folder, transform)\n\n# Split train dataset into train and validation sets\ntrain_indices, val_indices = train_test_split(list(range(len(train_dataset))), test_size=0.2, shuffle=True, stratify=train_dataset.targets)\ntrain_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\nval_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n\n# Create DataLoader for train and validation datasets\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\nval_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Load pre-trained ResNet50 model\nmodel = models.resnet50(pretrained=True)\n# # Load pre-trained ResNet50 model\n# model = models.resnet50(weights='imagenet')\n\n# Freeze all layers except the final fully connected layer\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes))\n\n# Define criterion and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Move model to GPU if available\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n\n# Train the model\nnum_epochs = 10\ntrain(model, criterion, optimizer, train_loader, val_loader, test_loader, num_epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:24:47.208618Z","iopub.execute_input":"2024-04-06T14:24:47.208975Z","iopub.status.idle":"2024-04-06T14:46:46.415753Z","shell.execute_reply.started":"2024-04-06T14:24:47.208948Z","shell.execute_reply":"2024-04-06T14:46:46.414813Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:02<00:00, 43.9MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Step [100/250], Loss: 1.3928\nEpoch [1/10], Step [200/250], Loss: 0.9851\nValidation Loss: 0.9032, Validation Accuracy: 71.25%\nEpoch [2/10], Step [100/250], Loss: 0.7915\nEpoch [2/10], Step [200/250], Loss: 0.8012\nValidation Loss: 0.8151, Validation Accuracy: 73.00%\nEpoch [3/10], Step [100/250], Loss: 0.7931\nEpoch [3/10], Step [200/250], Loss: 0.7667\nValidation Loss: 0.8202, Validation Accuracy: 74.00%\nEpoch [4/10], Step [100/250], Loss: 0.7399\nEpoch [4/10], Step [200/250], Loss: 0.7539\nValidation Loss: 0.7963, Validation Accuracy: 74.65%\nEpoch [5/10], Step [100/250], Loss: 0.7056\nEpoch [5/10], Step [200/250], Loss: 0.7503\nValidation Loss: 0.7910, Validation Accuracy: 74.85%\nEpoch [6/10], Step [100/250], Loss: 0.7206\nEpoch [6/10], Step [200/250], Loss: 0.7288\nValidation Loss: 0.7936, Validation Accuracy: 74.65%\nEpoch [7/10], Step [100/250], Loss: 0.6656\nEpoch [7/10], Step [200/250], Loss: 0.7027\nValidation Loss: 0.8178, Validation Accuracy: 73.65%\nEpoch [8/10], Step [100/250], Loss: 0.6853\nEpoch [8/10], Step [200/250], Loss: 0.6675\nValidation Loss: 0.8207, Validation Accuracy: 74.15%\nEpoch [9/10], Step [100/250], Loss: 0.6585\nEpoch [9/10], Step [200/250], Loss: 0.6837\nValidation Loss: 0.8113, Validation Accuracy: 73.95%\nEpoch [10/10], Step [100/250], Loss: 0.6595\nEpoch [10/10], Step [200/250], Loss: 0.6955\nValidation Loss: 0.8414, Validation Accuracy: 73.35%\nTest Loss: 0.0377, Test Accuracy: 74.25%\n","output_type":"stream"}]}]}